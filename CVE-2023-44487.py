"""
CVE-2023-44487 Vulnerability Scanner 
Developer: Aegisbyte
Website: https://www.aegisbyte.com
Contact Email: contact@aegisbyte.com
Date Released: October 10, 2023

The Python code provides a preliminary assessment of web servers for potential susceptibility to CVE-2023-44487.

Features:
1) Non-invasive evaluation of websites.
2) Tests for the acceptance of HTTP/2 requests without downgrade.
3) Tries to establish and subsequently reset a connection stream.

Interpretation:
If a web server both accepts HTTP/2 requests and permits the connection stream's establishment and resetting, it's conclusively vulnerable.
If it merely acknowledges HTTP/2 requests but fails the stream connection, potential vulnerability exists depending on server-side configurations.

Usage:
Install required dependencies:
$ python3 -m pip install httpx h2 requests

Run the scanner:
$ python CVE-2023-44487.py -i INPUT_URL.txt -o OUTPUT.csv
"""

import ssl
import csv
import socket
import httpx
import argparse
from h2.connection import H2Connection
from h2.config import H2Configuration
from http.client import HTTPConnection, HTTPSConnection
from urllib.parse import urlparse
from datetime import datetime


class IPAddress:
    PREFIX = "192.168.1."
    IPs = [PREFIX + str(i) for i in range(1, 255)]

    @classmethod
    def retrieve_ips(cls, proxy_detail):
        selected_ip = cls.IPs[0]
        with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as conn_socket:
            conn_socket.settimeout(2)
            try:
                conn_socket.connect(('8.8.8.8', 1))
                local_ip = conn_socket.getsockname()[0]
            except:
                local_ip = '127.0.0.1'
        return local_ip, selected_ip


def http2_status(target_url, proxy_detail):
    params = {'http2': True, 'verify': False}
    if proxy_detail:
        params['proxies'] = {
            'http://': proxy_detail['http'],
            'https://': proxy_detail['https']
        }
    try:
        with httpx.Client(**params) as client:
            response = client.get(target_url)
            if response.http_version == 'HTTP/2':
                return 1, ""
            return 0, response.http_version
    except Exception as e:
        return -1, str(e)


def reset_stream_action(host, port, stream_id, route='/', timeout_val=5, proxy_addr=None):
    ssl_params = ssl.create_default_context()
    ssl_params.check_hostname = False
    ssl_params.verify_mode = ssl.CERT_NONE

    connection = HTTPSConnection(host, port, timeout=timeout_val, context=ssl_params) if port == 443 else HTTPConnection(host, port, timeout=timeout_val)
    try:
        connection.connect()
        h2_config = H2Configuration(client_side=True)
        h2_conn = H2Connection(config=h2_config)
        h2_conn.initiate_connection()
        connection.send(h2_conn.data_to_send())

        headers = [(':method', 'GET'), (':authority', host), (':scheme', 'https'), (':path', route)]
        h2_conn.send_headers(stream_id, headers)
        connection.send(h2_conn.data_to_send())

        while True:
            chunk = connection.sock.recv(65535)
            if not chunk:
                break

            events = h2_conn.receive_data(chunk)
            for evt in events:
                if evt.stream_id == stream_id:
                    h2_conn.reset_stream(evt.stream_id)
                    connection.send(h2_conn.data_to_send())
                    return 1, ""
        return 0, "No response"
    except Exception as e:
        return -1, str(e)
    finally:
        connection.close()


def extract_url_data(url):
    parts = urlparse(url)
    return parts.hostname, parts.port or (443 if parts.scheme == 'https' else 80), parts.path or "/"


def main():
    parser = argparse.ArgumentParser(description="Check HTTP/2 support and potential vulnerabilities.")
    parser.add_argument('-i', '--input_file', required=True, help="Input file containing list of URLs.")
    parser.add_argument('-o', '--output_file', required=True, help="Output file for results.")
    parser.add_argument('--proxy_addr', help='HTTP/HTTPS proxy URL', default=None)
    args = parser.parse_args()

    proxy_data = {'http': args.proxy_addr, 'https': args.proxy_addr} if args.proxy_addr else {}

    local_ip, test_ip = IPAddress.retrieve_ips(proxy_data)

    try:
        with open(args.input_file, 'r') as in_file, open(args.output_file, 'w', newline='') as out_file:
            csv_writer = csv.writer(out_file)
            csv_writer.writerow(['Timestamp', 'Local IP', 'Test IP', 'URL', 'Status', 'Details'])

            for line in in_file:
                web_address = line.strip()
                if web_address:
                    time_now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    support_status, err_msg = http2_status(web_address, proxy_data)
                    domain, port_num, path = extract_url_data(web_address)

                    if support_status == 1:
                        result, err_detail = reset_stream_action(domain, port_num, 1, path, proxy_addr=args.proxy_addr)
                        if result == 1:
                            csv_writer.writerow([time_now, local_ip, test_ip, web_address, 'VULNERABLE', ''])
                        else:

                            csv_writer.writerow([time_now, local_ip, test_ip, web_address, 'POSSIBLE', f'Error in reset: {err_detail}'])
                    elif support_status == 0:
                        csv_writer.writerow([time_now, local_ip, test_ip, web_address, 'NOT SUPPORTED', err_msg])
                    else:
                        csv_writer.writerow([time_now, local_ip, test_ip, web_address, 'ERROR', err_msg])

            print(f"Results successfully written to: {args.output_file}")

    except FileNotFoundError:
        print(f"Error: The input file {args.input_file} was not found.")
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
if __name__ == "__main__":
    main()
